{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input,Conv2D,MaxPool2D,Flatten,Dense\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam ,RMSprop,Adagrad,Adadelta\n",
    "import scipy.io as sio\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    l0=2031\n",
    "    l1=1896\n",
    "    l2=1962\n",
    "    l3=1963\n",
    "    l4=2025\n",
    "\n",
    "##################\n",
    "   \n",
    "#     data=sio.loadmat('/Users/apple/Documents/MATLAB/井中微地震监测/DATA_Augment_6.20/DATApy.mat')\n",
    "#      data=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy.mat')\n",
    "    data1=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy1.mat')\n",
    "    data2=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy2.mat')\n",
    "    data3=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy3.mat')\n",
    "    data4=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy4.mat')\n",
    "    data5=sio.loadmat('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy5.mat')\n",
    "\n",
    "    data1 = data1['DATApy1']    # 大小为(x, 1001, 12, 3)\n",
    "    data2 = data2['DATApy2']    # 大小为(x, 1001, 12, 3)\n",
    "    data3 = data3['DATApy3']    # 大小为(x, 1001, 12, 3)\n",
    "    data4 = data4['DATApy4']    # 大小为(x, 1001, 12, 3)\n",
    "    data5 = data5['DATApy5']    # 大小为(x, 1001, 12, 3)\n",
    "    \n",
    "    # 将五个数组沿着第一个维度拼接\n",
    "    data = np.concatenate((data1,data2, data3, data4, data5 ),axis=0)\n",
    "\n",
    "#     data=h5py.File('/Users/apple/Documents/MATLAB/本科毕业论文/DATApy.mat','r')\n",
    "    tr_num_1=l0\n",
    "    tr_num_2=l1+tr_num_1\n",
    "    tr_num_3=l2+tr_num_2\n",
    "    tr_num_4=l3+tr_num_3\n",
    "    tr_num_5=l4+tr_num_4\n",
    "\n",
    "    tr_num_11=l0\n",
    "    tr_num_22=l1\n",
    "    tr_num_33=l2\n",
    "    tr_num_44=l3\n",
    "    tr_num_55=l4\n",
    "    \n",
    "#     x_train_1=data['DATApy'][0:tr_num_1]\n",
    "#     x_train_2=data['DATApy'][tr_num_1:tr_num_2]\n",
    "#     x_train_3=data['DATApy'][tr_num_2:tr_num_3]\n",
    "#     x_train_4=data['DATApy'][tr_num_3:tr_num_4]\n",
    "#     x_train_5=data['DATApy'][tr_num_4:tr_num_5]\n",
    "\n",
    "    x_train_1=data[0:tr_num_1,:,:,:]\n",
    "    x_train_2=data[tr_num_1:tr_num_2,:,:,:]\n",
    "    x_train_3=data[tr_num_2:tr_num_3,:,:,:]\n",
    "    x_train_4=data[tr_num_3:tr_num_4,:,:,:]\n",
    "    x_train_5=data[tr_num_4:tr_num_5,:,:,:]\n",
    "    \n",
    "    y_train_1=[[1,0,0,0,0]]*tr_num_11\n",
    "    y_train_2=[[0,1,0,0,0]]*tr_num_22\n",
    "    y_train_3=[[0,0,1,0,0]]*tr_num_33\n",
    "    y_train_4=[[0,0,0,1,0]]*tr_num_44\n",
    "    y_train_5=[[0,0,0,0,1]]*tr_num_55\n",
    "\n",
    "\n",
    "    \n",
    "    x_train=np.concatenate((x_train_1,x_train_2,x_train_3,x_train_4,x_train_5))\n",
    "    y_train=np.concatenate((y_train_1,y_train_2,y_train_3,y_train_4,y_train_5))\n",
    "    \n",
    "    return (x_train,y_train)\n",
    "    \n",
    "#     return (x_train,y_train),(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data,ydata,seed=1.0):\n",
    "    index=[i for i in range(len(ydata))]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(index)\n",
    "    data = [data[i] for i in index]\n",
    "    ydata = [ydata[i] for i in index]\n",
    "    return np.array(data),np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ntrc(data):\n",
    "    dmax=data.max()\n",
    "#     for i,data1 in enumerate(data):\n",
    "#         plt.plot(data1[:]+i*dmax)\n",
    "    for i,data1 in enumerate(data):\n",
    "        for ii in [0, 1, 2]:\n",
    "            if ii==0:\n",
    "#                  plt.plot(data1[:,ii]+i*dmax,'mediumpurple')\n",
    "                 plt.plot(data1[:,ii]+i*dmax,'r')\n",
    "\n",
    "            if ii==1:\n",
    "#                  plt.plot(data1[:,ii]+i*dmax,'lightcoral')\n",
    "                 plt.plot(data1[:,ii]+i*dmax,'b')\n",
    "\n",
    "            if ii==2:\n",
    "#                  plt.plot(data1[:,ii]+i*dmax,'cadetblue')\n",
    "                 plt.plot(data1[:,ii]+i*dmax,'g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_accuracy = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_accuracy['batch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_accuracy['epoch'].append(logs.get('val_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "\n",
    "        # acc\n",
    "#         plt.figure(figsize=(7, 5))\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train accuracy')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_accuracy[loss_type], 'b', label='val accuracy')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "#         plt.legend(loc=\"best\")\n",
    "        plt.legend(loc='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('训练过程.png',dpi=1200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detectevent():\n",
    "#     def __init__(self):\n",
    "#         (x_train,y_train),(x_test,y_test)=load_data()\n",
    "        \n",
    "#         (x,y)=load_data()\n",
    "#         (x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.2)\n",
    "#         (x_train,y_train)=shuffle_data(x_train,y_train)\n",
    "#         (x_test,y_test)=shuffle_data(x_test,y_test)\n",
    "        \n",
    "#         self.x_train,self.y_train=shuffle_data(x_train,y_train)\n",
    "#         self.x_test=x_test\n",
    "#         self.y_test = y_test\n",
    "#         print('shape',x_train.shape,y_train.shape)\n",
    "\n",
    "#     def get_cnn(self):\n",
    "#         inputs = Input((12, 1001, 3))\n",
    "#         conv1 = Conv2D(16, kernel_size=(3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "#         conv1 = MaxPool2D(pool_size=(2,4))(conv1)\n",
    "        \n",
    "#         conv2 = Conv2D(32, kernel_size=(3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "#         conv2 = MaxPool2D(pool_size=(2,2))(conv2)\n",
    "#         conv2 = Flatten()(conv2)\n",
    "        \n",
    "#         dense=Dense(128,activation='relu')(conv2)\n",
    "#         dense=Dense(5,activation='softmax')(dense)\n",
    "        \n",
    "#         model = Model(input = inputs, outputs = dense)\n",
    "#         model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#         return model\n",
    "\n",
    "    def train(self):\n",
    "        model=self.get_cnn()\n",
    "        model.summary()\n",
    "        model_checkpoint = ModelCheckpoint('network1.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\n",
    "        model.fit(self.x_train,self.y_train, batch_size=4, nb_epoch=20, verbose=1,validation_split=0.25, \n",
    "                   shuffle=True, callbacks=[model_checkpoint])\n",
    "    def test(self):\n",
    "        model=load_model('network1.hdf5')\n",
    "        y_predict=model.predict(self.x_test[0::3])\n",
    "        print('predict:',y_predict)\n",
    "        print('true:',self.y_test[0::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y)=load_data()\n",
    "# x = np.transpose(x, (3, 2, 1, 0)) #通过h5py读取的数据维度排列调转了(使用h5py才使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "(x_train,y_train)=shuffle_data(x_train,y_train)\n",
    "(x_test,y_test)=shuffle_data(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Detectevent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Conv2D(filters=64, kernel_size=(3, 3),padding='valid', activation='relu', input_shape=(12, 1001,3),\n",
    "                          name=\"conv1\"))\n",
    "# network.add(BatchNormalization(epsilon=0.0001, momentum=0.9))\n",
    "network.add(layers.MaxPooling2D((2,2)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "network.add(layers.Conv2D(filters=128, kernel_size=(3, 3),padding='valid', activation='relu',name=\"conv2\"))\n",
    "# network.add(BatchNormalization(epsilon=0.0001, momentum=0.9))\n",
    "network.add(layers.MaxPooling2D((2, 2)))\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "network.add(layers.Flatten())\n",
    "\n",
    "\n",
    "network.add(layers.Dense(128, activation='relu',name=\"dense4\"))\n",
    "\n",
    "network.add(layers.Dense(64, activation='relu',name=\"dense5\"))\n",
    "\n",
    "network.add(layers.Dense(5, activation='softmax',name=\"dense6\"))\n",
    "\n",
    "network.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('network1.hdf5',\n",
    "                             monitor='val_accuracy', save_weights_only=True,verbose=1,save_best_only=True, period=1,mode='max')\n",
    "# 定义 EarlyStopping 回调函数\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=6)\n",
    "\n",
    "history = LossHistory()\n",
    "# callbacks=[history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-excellence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.fit(x_train,y_train,epochs=30,  batch_size=32,validation_data=(x_test, y_test),callbacks=[history],shuffle=True)\n",
    "\n",
    "# network.fit(x_train,y_train,epochs=30,  batch_size=64,validation_data=(x_test, y_test),callbacks=[early_stopping ],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save('model/my_network_4.4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = network.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-harassment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-switzerland",
   "metadata": {},
   "source": [
    "# 评价精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-aaron",
   "metadata": {},
   "source": [
    "## 1、混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.preprocessing import Normalizer\n",
    "matplotlib.rc(\"font\",family='SimHei') # 中文字体\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 禹行精选配色方案\n",
    "# Blues\n",
    "# BuGn\n",
    "# Reds\n",
    "# Greens\n",
    "# Greys\n",
    "# binary\n",
    "# Oranges\n",
    "# Purples\n",
    "# BuPu\n",
    "# GnBu\n",
    "# OrRd\n",
    "# RdPu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens,#这个主题看着就干净~\n",
    "                          normalize=True):\n",
    "   \n",
    " \n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Greens')\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    \n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.3f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.colorbar()\n",
    "    plt.savefig('混淆矩阵.png',dpi=1000)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confuse_nor(model, x_val, y_val):\n",
    "    predictions = network.predict_classes(x_val,batch_size=5)\n",
    "    truelabel = y_val.argmax(axis=-1)   # 将one-hot转化为label\n",
    "    conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)\n",
    "    conf_mat=Normalizer().fit_transform(conf_mat)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(conf_mat, normalize=True,target_names=labels,title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['1','2','3','4','5']\n",
    "plot_confuse_nor(model, x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-council",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confuse(model, x_val, y_val):\n",
    "    predictions = network.predict_classes(x_val,batch_size=5)\n",
    "    truelabel = y_val.argmax(axis=-1)   # 将one-hot转化为label\n",
    "    conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(conf_mat, normalize=False,target_names=labels,title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confuse(model, x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-myrtle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-mounting",
   "metadata": {},
   "source": [
    "## 绘制ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/Users/apple/Desktop/本科毕业论文/类别.csv')\n",
    "classes = df['标注类别名称'].unique()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = np.unique(df['标注类别名称'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(class_list) # 测试集标签类别数\n",
    "# palette = sns.hls_palette(n_class) # 配色方案 \n",
    "palet = sns.hls_palette(n_class, l=.4, s=1)\n",
    "\n",
    "# sns.palplot(palette)\n",
    "sns.palplot(palet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-mount",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-yacht",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "n_classes=5\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    y_score= network.predict(x_test)\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = palet\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i+1, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC曲线.png',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-haven",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.xlim(0, 0.04)\n",
    "plt.ylim(0.96, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = palet\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i+1, roc_auc[i]))\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC曲线局部.png',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-wrong",
   "metadata": {},
   "source": [
    "## 绘制PR曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制多分类PR曲线\n",
    "plt.figure(figsize=(7, 7))\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "n_classes = 5\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "plt.rcParams['font.family']=['Times New Roman']\n",
    "\n",
    "lw = 2\n",
    "colors = palet\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(precision[i], recall[i], color=color, lw=lw,\n",
    "             label='PR curve of class {0}'.format(i+1))\n",
    "\n",
    "plt.plot([1, 0], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Precision recall curve for multi-class data')\n",
    "plt.legend(loc=\"lower left\")\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "plt.savefig('PR曲线.png',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "n_classes = 5\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], thresholds = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='Class {0}'.format(i+1), color=palet[i])\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "# 添加颜色条\n",
    "sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=plt.Normalize(vmin=0, vmax=1))\n",
    "sm.set_array(thresholds)\n",
    "plt.colorbar(sm, label='Threshold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制多分类PR曲线\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.xlim(0.93, 1)\n",
    "plt.ylim(0.93, 1)\n",
    "plt.rcParams['font.family']=['Times New Roman']\n",
    "\n",
    "lw = 2\n",
    "colors = palet\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(precision[i], recall[i], color=color, lw=lw,\n",
    "             label='PR curve of class {0}'.format(i+1))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Precision recall curve for multi-class data')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('PR曲线局部.png',dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-costa",
   "metadata": {},
   "source": [
    "\n",
    "$MSE=\\frac{1}{N}\\sum_{i=1}^{N}\\left(Y_i-f\\left(X_i\\right)\\right)^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-israel",
   "metadata": {},
   "source": [
    "# 预测错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 对测试集进行预测\n",
    "y_pred = network.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到预测错误的样本\n",
    "incorrect = np.nonzero(y_pred.argmax(axis=1) != y_test.argmax(axis=1))[0]\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[incorrect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[incorrect].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-picking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred[incorrect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-distribution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 可视化预测错误的样本\n",
    "L=incorrect\n",
    "for ii in list(range(len(L))):\n",
    "    plt.figure(ii)\n",
    "    plot_ntrc(x_test[L[ii]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-biodiversity",
   "metadata": {},
   "source": [
    "# 类别分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1=[x for x,y in enumerate(y_test) if y_test[x][0] == 1]\n",
    "L2=[x for x,y in enumerate(y_test) if y_test[x][1] == 1]\n",
    "L3=[x for x,y in enumerate(y_test) if y_test[x][2] == 1]\n",
    "L4=[x for x,y in enumerate(y_test) if y_test[x][3] == 1]\n",
    "L5=[x for x,y in enumerate(y_test) if y_test[x][4] == 1]\n",
    "L=[L1 ,L2,L3, L4 ,L5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=L2\n",
    "for ii in list(range(300)):\n",
    "    plt.figure(ii)\n",
    "    plot_ntrc(x_test[L[ii]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-final",
   "metadata": {},
   "source": [
    "# 使用验证集选择阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=x_test\n",
    "y_val=y_test\n",
    "y_val_pred =network.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 网格搜索最佳阈值\n",
    "# num_classes=5\n",
    "# num_thresholds=20\n",
    "# thresholds = np.linspace(0, 1, num_thresholds)\n",
    "# best_thresholds = [0.0] * num_classes\n",
    "# best_scores = [0.0] * num_classes\n",
    "# for i in range(num_classes):\n",
    "#     y_val_pred = network.predict(X_val)\n",
    "#     val_scores = []\n",
    "#     for t in thresholds:\n",
    "#         y_val_pred_thresholded = (y_val_pred[:, i] >= t).astype(int)\n",
    "#         val_score = f1_score(y_val[:, i], y_val_pred_thresholded)\n",
    "#         val_scores.append(val_score)\n",
    "#     best_index = np.argmax(val_scores)\n",
    "#     best_thresholds[i] = thresholds[best_index]\n",
    "#     best_scores[i] = val_scores[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置字体\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# 网格搜索最佳阈值\n",
    "num_classes = 5\n",
    "num_thresholds = 20\n",
    "thresholds = np.linspace(0, 1, num_thresholds)\n",
    "best_thresholds = [0.0] * num_classes\n",
    "best_scores = [0.0] * num_classes\n",
    "\n",
    "# 初始化画布\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# 循环处理每个类别\n",
    "for i in range(num_classes):\n",
    "    y_val_pred = network.predict(X_val)\n",
    "    val_scores = []\n",
    "    for t in thresholds:\n",
    "        y_val_pred_thresholded = (y_val_pred[:, i] >= t).astype(int)\n",
    "        val_score = f1_score(y_val[:, i], y_val_pred_thresholded)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    best_index = np.argmax(val_scores)\n",
    "    best_thresholds[i] = thresholds[best_index]\n",
    "    best_scores[i] = val_scores[best_index]\n",
    "    \n",
    "   \n",
    "     # 绘制当前类别的阈值搜索过程\n",
    "    line_color = sns.color_palette()[i % len(sns.color_palette())]\n",
    "    ax.plot(thresholds, val_scores, linewidth=2, label='F1 score of C{0}'.format(i+1), color=line_color)\n",
    "    ax.scatter(best_thresholds[i], best_scores[i], s=50, color=line_color, edgecolors='black', zorder=3)\n",
    "    ax.axvline(x=best_thresholds[i], linestyle='--', color=line_color, alpha=0.5)\n",
    "#     ax.text(best_thresholds[i], best_scores[i], \" C{} {:.3f}\".format(i+1,best_thresholds[i]), fontsize=12, ha='center', va='top')\n",
    "    \n",
    "    \n",
    "# 添加全局标题和坐标轴标签\n",
    "plt.title('Threshold Selection', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Threshold', fontsize=14)\n",
    "plt.ylabel('F1 Score', fontsize=14)\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.9, 1.01)   \n",
    "\n",
    "# 添加图例和背景网格\n",
    "ax.legend(frameon=True, facecolor='white', framealpha=0.9, fontsize=12)\n",
    "ax.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# 设置坐标轴标签的字体和刻度\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0.9, 1.005, 0.01))\n",
    "\n",
    "# 调整图像边界和填充\n",
    "plt.tight_layout(pad=3.0, rect=[0.03, 0.03, 0.97, 0.97])\n",
    "plt.savefig('阈值选择.png',dpi=1000)\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-house",
   "metadata": {},
   "source": [
    "#  减维可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = Model(inputs=network.input,outputs=network.get_layer('dense5').output)\n",
    "# result = middle.predict(x_test)[0]\n",
    "result = middle.predict(x_test)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/Users/apple/Desktop/本科毕业论文/类别.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['标注类别名称'].unique()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = np.unique(df['标注类别名称'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "marker_list = ['<', 'o', 'v', '^','p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(class_list) # 测试集标签类别数\n",
    "# palette = sns.hls_palette(n_class) # 配色方案 \n",
    "palet = sns.hls_palette(n_class, l=.4, s=1)\n",
    "\n",
    "# sns.palplot(palette)\n",
    "sns.palplot(palet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed(1234)\n",
    "# random.shuffle(marker_list)\n",
    "# random.shuffle(palet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "honey-conclusion",
   "metadata": {},
   "source": [
    "# T-SNE二维可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=load_model('model/my_network_4.3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, n_iter=1000)\n",
    "X_tsne_2d = tsne.fit_transform(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1=[x for x,y in enumerate(y_test) if y_test[x][0] == 1]\n",
    "L2=[x for x,y in enumerate(y_test) if y_test[x][1] == 1]\n",
    "L3=[x for x,y in enumerate(y_test) if y_test[x][2] == 1]\n",
    "L4=[x for x,y in enumerate(y_test) if y_test[x][3] == 1]\n",
    "L5=[x for x,y in enumerate(y_test) if y_test[x][4] == 1]\n",
    "L=[L1 ,L2,L3, L4 ,L5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[L1 ,L2,L3, L4 ,L5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同的 符号 表示 不同的 标注类别\n",
    "show_feature = '标注类别名称'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-relief",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for idx, fruit in enumerate(class_list): # 遍历每个类别\n",
    "    # 获取颜色和点型\n",
    "    color = palet[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "    \n",
    "    # 找到所有标注类别为当前类别的图像索引号\n",
    "    indices = L[idx]\n",
    "\n",
    "    plt.scatter(X_tsne_2d[indices, 0], X_tsne_2d[indices, 1], color=color, marker=marker, label=fruit, alpha=0.2,s=150)\n",
    "\n",
    "plt.legend(fontsize=16, markerscale=1, bbox_to_anchor=(1, 1),framealpha=0.5)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('语义特征t-SNE二维降维可视化.png', dpi=1200) # 保存图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-breeding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=198\n",
    "\n",
    "\n",
    "plot_ntrc(x_train[a])\n",
    "print('label:',y_train[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for idx, fruit in enumerate(class_list): # 遍历每个类别\n",
    "    # 获取颜色和点型\n",
    "    color = palet[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "    \n",
    "    # 找到所有标注类别为当前类别的图像索引号\n",
    "    indices = L[idx]\n",
    "\n",
    "    plt.scatter(X_tsne_2d[indices, 0], X_tsne_2d[indices, 1], color=color, marker=marker, label=fruit, alpha=0.3,s=150)\n",
    "plt.scatter(X_tsne_2d[a, 0], X_tsne_2d[a, 1], color='r', marker='x', label='c_point', alpha=1,s=600)\n",
    "plt.legend(fontsize=16, markerscale=1, bbox_to_anchor=(1, 1),framealpha=0.5)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('语义特征t-SNE二维降维可视化2.pdf', dpi=1200) # 保存图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-cedar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-thunder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-pathology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "knowing-morning",
   "metadata": {},
   "source": [
    "# PCA二维可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "x = result\n",
    "pca = PCA(n_components=2)  # 加载PCA算法，设置降维后主成分数目为2\n",
    "reduced_x = pca.fit_transform(x)  # 对样本进行降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-office",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for idx, fruit in enumerate(class_list): # 遍历每个类别\n",
    "    # 获取颜色和点型\n",
    "    color = palet[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "    \n",
    "    # 找到所有标注类别为当前类别的图像索引号\n",
    "    indices = L[idx]\n",
    "\n",
    "    plt.scatter(reduced_x[indices, 0], reduced_x[indices, 1], color=color, marker=marker, label=fruit,  alpha=0.5,s=50)\n",
    "\n",
    "plt.legend(fontsize=16, markerscale=3, bbox_to_anchor=(1, 1),framealpha=0.5)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig('语义特征PCA二维降维可视化.pdf', dpi=1200) # 保存图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-google",
   "metadata": {},
   "source": [
    "# 可视化卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.layers[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可视化卷积层\n",
    "conv_layer = network.layers[0]  # 获取卷积层\n",
    "filters = conv_layer.get_weights()[0]  # 获取卷积层的权重\n",
    "filters = np.transpose(filters, (3, 0, 1, 2))  # 调整维度顺序，使其适合imshow函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(8, 4))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 32:\n",
    "        ax.imshow(filters[i, :, :, 0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('卷积层.png', dpi=1200) # 保存图像\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化卷积层\n",
    "conv_layer = network.layers[3]  # 获取卷积层\n",
    "filters = conv_layer.get_weights()[0]  # 获取卷积层的权重\n",
    "filters = np.transpose(filters, (3, 0, 1, 2))  # 调整维度顺序，使其适合imshow函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(8, 4))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 32:\n",
    "        ax.imshow(filters[i, :, :, 0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-perth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
